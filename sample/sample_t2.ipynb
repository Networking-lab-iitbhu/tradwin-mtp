{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "from geopy import distance\n",
    "import torch\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weather stuff\n",
    "import pandas as pd\n",
    "cols = ['rain', 'temp', 'rhum']\n",
    "\n",
    "w1 = None\n",
    "w2 = None\n",
    "w3 = None\n",
    "\n",
    "def setup_weather_dfs():\n",
    "    global w1, w2, w3\n",
    "    w1 = pd.read_csv(\"./datasets/scats/2023/3m/w1.csv\")\n",
    "    w2 = pd.read_csv(\"./datasets/scats/2023/3m/w2.csv\")\n",
    "    w3 = pd.read_csv(\"./datasets/scats/2023/3m/w3.csv\")\n",
    "    # drop useless rows to speed up\n",
    "    w1 = w1.drop(w1.index[:520000])\n",
    "    w2 = w2.drop(w2.index[:160000])\n",
    "    w3 = w3.drop(w3.index[:520000])\n",
    "\n",
    "setup_weather_dfs()\n",
    "\n",
    "import geopy.distance as distance\n",
    "\n",
    "def get_df_closest(lat, long):\n",
    "    coords = {\n",
    "        \"w1\": (53.306, -6.439),\n",
    "        \"w2\": (53.364, -6.350),\n",
    "        \"w3\": (53.428, -6.241)\n",
    "    }\n",
    "    def get_dist_lat_long(lat1, long1, lat2, long2):\n",
    "        return distance.distance((lat1, long1), (lat2, long2)).m\n",
    "    min_dist = float(\"inf\")\n",
    "    closest = None\n",
    "    for key, val in coords.items():\n",
    "        dist = get_dist_lat_long(lat, long, val[0], val[1])\n",
    "        if dist < min_dist:\n",
    "            min_dist = dist\n",
    "            closest = key\n",
    "    if closest == \"w1\":\n",
    "        return w1\n",
    "    elif closest == \"w2\":\n",
    "        return w2\n",
    "    elif closest == \"w3\":\n",
    "        return w3\n",
    "    else:\n",
    "        raise ValueError(\"Invalid closest\")\n",
    "    \n",
    "def get_weather(month, day, hour, lat, long):\n",
    "    df = get_df_closest(lat, long)\n",
    "    day_pad = str(day).zfill(2)\n",
    "    hour_pad = str(hour).zfill(2)\n",
    "    month_str = None\n",
    "    if month == 10:\n",
    "        month_str = \"oct\"\n",
    "    elif month == 11:\n",
    "        month_str = \"nov\"\n",
    "    elif month == 12:\n",
    "        month_str = \"dec\"\n",
    "    else:\n",
    "        raise ValueError(\"Invalid month\")\n",
    "    date = f\"{day_pad}-{month_str}-2023 {hour_pad}:00\"\n",
    "    row = df.loc[df['date'] == date]\n",
    "    row = row.iloc[0]\n",
    "    array = row[cols].values\n",
    "    array = [float(x) for x in array]\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "from geopy import distance\n",
    "import torch\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "class Handler:\n",
    "    def __init__(self):\n",
    "        self.n_nodes = 609\n",
    "        self.df_path = \"./datasets/scats/2023/3m/processed.csv\"\n",
    "        self.df = pd.read_csv(self.df_path)\n",
    "        self.prox = 20\n",
    "        self.site_lat_long = site_lat_long = self.df.groupby(\"Site\")[[\"Lat\", \"Long\"]].first()\n",
    "\n",
    "        n_closest = self.prox\n",
    "        closest = [[] for i in range(self.n_nodes)]\n",
    "        for i in range(self.n_nodes):\n",
    "            cur_dists = []\n",
    "            for j in range(self.n_nodes):\n",
    "                lati = self.get_lat_node_id(i)\n",
    "                longi = self.get_long_node_id(i)\n",
    "                latj = self.get_lat_node_id(j)\n",
    "                longj = self.get_long_node_id(j)\n",
    "                dist = self.get_dist_lat_long(lati, longi, latj, longj)\n",
    "                cur_dists.append((dist, j))\n",
    "            cur_dists.sort()\n",
    "            # taket the top n_closest\n",
    "            for j in range(n_closest):\n",
    "                closest[i].append(cur_dists[j][1])\n",
    "\n",
    "        self.closest = closest\n",
    "\n",
    "        def centre_i_neighbours(i):\n",
    "            lt = sum(self.get_lat_node_id(j) for j in closest[i]) / n_closest\n",
    "            lg = sum(self.get_long_node_id(j) for j in closest[i]) / n_closest\n",
    "            return lt, lg\n",
    "        \n",
    "        self.centre_of_i_neighbours = [centre_i_neighbours(i) for i in range(self.n_nodes)]\n",
    "\n",
    "        def get_closest_to_centre(i):\n",
    "            centre = centre_i_neighbours(i)\n",
    "            cur_dists = []\n",
    "            for j in closest[i]:\n",
    "                dist = self.get_dist_lat_long(centre[0], centre[1], self.get_lat_node_id(j), self.get_long_node_id(j))\n",
    "                cur_dists.append((dist, j))\n",
    "            cur_dists.sort()\n",
    "            return list(map(lambda x: x[1], cur_dists))\n",
    "        \n",
    "        self.closest_ct_close = [get_closest_to_centre(i) for i in range(self.n_nodes)]\n",
    "\n",
    "        self.df_time_type = self.df.copy()\n",
    "        self.df_time_type['Time'] = pd.to_datetime(self.df['Time'])\n",
    "\n",
    "        self.load_graph_emb()\n",
    "\n",
    "    def sample(self):\n",
    "        i = random.randint(0, self.n_nodes)\n",
    "        return self.closest_ct_close[i]\n",
    "\n",
    "    def regen(self):\n",
    "        self.df = pd.read_csv(self.df_path)\n",
    "\n",
    "    def set_prox(self, prox):\n",
    "        self.prox = prox\n",
    "\n",
    "    def get_dist_lat_long(self, lat1, long1, lat2, long2):\n",
    "        return distance.distance((lat1, long1), (lat2, long2)).m\n",
    "\n",
    "    def get_lat_node_id(self, i):\n",
    "        return self.site_lat_long.loc[i, \"Lat\"]\n",
    "    \n",
    "    def get_long_node_id(self, i):\n",
    "        return self.site_lat_long.loc[i, \"Long\"]\n",
    "    \n",
    "    def sample_node(self):\n",
    "        return random.randint(0, self.n_nodes-1)\n",
    "    \n",
    "    def sample_time(self):\n",
    "        return random.choice(self.df_time_type['Time'])\n",
    "    \n",
    "    def get_series(self, node, time, len):\n",
    "        site = self.df_time_type[self.df_time_type['Site'] == node]\n",
    "        vols = []\n",
    "        for i in range(len):\n",
    "            vol = site[site['Time'] == time]['Volume']\n",
    "            if vol.empty:\n",
    "                vols.append(0)\n",
    "            else:\n",
    "                vols.append(vol.iloc[0])\n",
    "            time += pd.Timedelta(hours=1)\n",
    "        return vols\n",
    "    \n",
    "    def load_graph_emb(self):\n",
    "        emb_path = \"./datasets/scats/2023/3m/graph_emb_3m.pt\"\n",
    "        self.embeddings = torch.load(emb_path, map_location=torch.device('cpu'))\n",
    "\n",
    "    def get_gemb(self, i):\n",
    "        return self.embeddings[i]\n",
    "    \n",
    "    def text_time_to_datetime(self, text_time):\n",
    "        time_obj = datetime.strptime(text_time, \"%Y-%m-%d %H:%M:%S\")\n",
    "        return time_obj\n",
    "    \n",
    "    def datetime_to_text_time(self, time_obj):\n",
    "        return time_obj.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    \n",
    "    def encode_time(self, time_obj):\n",
    "        hour = time_obj.hour\n",
    "        month = time_obj.month\n",
    "        day = time_obj.day\n",
    "        weekday_or_weekend = 0 if time_obj.weekday() < 5 else 1\n",
    "        features_tensor = torch.tensor([hour, day, month, weekday_or_weekend], dtype=torch.float32)\n",
    "        return features_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = Handler()\n",
    "h.sample_node()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "miss_rate = .1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feat_one(node, time):\n",
    "    emb = h.get_gemb(node)\n",
    "    time_ft = h.encode_time(time)\n",
    "    delta = 1\n",
    "    len = 3\n",
    "    qlen = 4\n",
    "    series = h.get_series(node, time, qlen)\n",
    "    xval = series[:len]\n",
    "    yval = series[len:]\n",
    "\n",
    "    xt = torch.cat([emb, torch.tensor(xval, dtype=torch.float32), time_ft])\n",
    "    yt = torch.tensor(yval, dtype=torch.float32)\n",
    "\n",
    "    return xt,yt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_one():\n",
    "    node, time = h.sample_node(), h.sample_time()\n",
    "    len = 3\n",
    "    qlen = 4\n",
    "    nodes = h.closest_ct_close[node]\n",
    "\n",
    "    X = []\n",
    "    Y = []\n",
    "\n",
    "    for i in nodes:\n",
    "        x,y = feat_one(i, time)\n",
    "        X.append(x)\n",
    "        Y.append(y)\n",
    "    \n",
    "    X = torch.stack(X)\n",
    "    Y = torch.cat(Y)\n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = sample_one()\n",
    "display(a.shape, b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_n(n):\n",
    "    X = []\n",
    "    Y = []\n",
    "    for i in range(n):\n",
    "        x,y = sample_one()\n",
    "        X.append(x)\n",
    "        Y.append(y)\n",
    "    X = torch.stack(X)\n",
    "    Y = torch.stack(Y)\n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100\n",
    "X,Y = sample_n(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(X.shape, Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntrain = 1000\n",
    "ntest = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX, trainY = sample_n(ntrain)\n",
    "testX, testY = sample_n(ntest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = \"./datasets/scats/2023/3m/t2\"\n",
    "torch.save(trainX, f\"{base}_tr1kx.pt\")\n",
    "torch.save(trainY, f\"{base}_tr1ky.pt\")\n",
    "torch.save(testX, f\"{base}_tr1tx.pt\")\n",
    "torch.save(testY, f\"{base}_tr1ty.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save as is,apply missing while train"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
