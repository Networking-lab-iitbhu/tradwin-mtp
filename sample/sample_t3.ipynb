{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "take a group of 13 nodes closest nodes, and mask out the 3 in the centre\n",
    "1. select a random node\n",
    "2. find the 12 closest nodes\n",
    "3. figure out the centre\n",
    "4. find 3 nodes closest to the centre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weather stuff\n",
    "import pandas as pd\n",
    "cols = ['rain', 'temp', 'rhum']\n",
    "\n",
    "w1 = None\n",
    "w2 = None\n",
    "w3 = None\n",
    "\n",
    "def setup_weather_dfs():\n",
    "    global w1, w2, w3\n",
    "    w1 = pd.read_csv(\"./datasets/scats/2023/3m/w1.csv\")\n",
    "    w2 = pd.read_csv(\"./datasets/scats/2023/3m/w2.csv\")\n",
    "    w3 = pd.read_csv(\"./datasets/scats/2023/3m/w3.csv\")\n",
    "    # drop useless rows to speed up\n",
    "    w1 = w1.drop(w1.index[:520000])\n",
    "    w2 = w2.drop(w2.index[:160000])\n",
    "    w3 = w3.drop(w3.index[:520000])\n",
    "\n",
    "setup_weather_dfs()\n",
    "\n",
    "import geopy.distance as distance\n",
    "\n",
    "def get_df_closest(lat, long):\n",
    "    coords = {\n",
    "        \"w1\": (53.306, -6.439),\n",
    "        \"w2\": (53.364, -6.350),\n",
    "        \"w3\": (53.428, -6.241)\n",
    "    }\n",
    "    def get_dist_lat_long(lat1, long1, lat2, long2):\n",
    "        return distance.distance((lat1, long1), (lat2, long2)).m\n",
    "    min_dist = float(\"inf\")\n",
    "    closest = None\n",
    "    for key, val in coords.items():\n",
    "        dist = get_dist_lat_long(lat, long, val[0], val[1])\n",
    "        if dist < min_dist:\n",
    "            min_dist = dist\n",
    "            closest = key\n",
    "    if closest == \"w1\":\n",
    "        return w1\n",
    "    elif closest == \"w2\":\n",
    "        return w2\n",
    "    elif closest == \"w3\":\n",
    "        return w3\n",
    "    else:\n",
    "        raise ValueError(\"Invalid closest\")\n",
    "    \n",
    "def get_weather(month, day, hour, lat, long):\n",
    "    df = get_df_closest(lat, long)\n",
    "    day_pad = str(day).zfill(2)\n",
    "    hour_pad = str(hour).zfill(2)\n",
    "    month_str = None\n",
    "    if month == 10:\n",
    "        month_str = \"oct\"\n",
    "    elif month == 11:\n",
    "        month_str = \"nov\"\n",
    "    elif month == 12:\n",
    "        month_str = \"dec\"\n",
    "    else:\n",
    "        raise ValueError(\"Invalid month\")\n",
    "    date = f\"{day_pad}-{month_str}-2023 {hour_pad}:00\"\n",
    "    row = df.loc[df['date'] == date]\n",
    "    row = row.iloc[0]\n",
    "    array = row[cols].values\n",
    "    array = [float(x) for x in array]\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "from geopy import distance\n",
    "import torch\n",
    "import numpy as np\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_path = \"./datasets/scats/2023/3m/processed.csv\"\n",
    "df = pd.read_csv(df_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_nodes = df[\"Site\"].nunique()\n",
    "n_nodes\n",
    "# nodes from 0 to 608"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get lat long pair for each site_id\n",
    "site_lat_long = df.groupby(\"Site\")[[\"Lat\", \"Long\"]].first()\n",
    "site_lat_long.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing closest nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for each node find and store the `n_closest` nodes closest to it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dist_lat_long(lat1, long1, lat2, long2):\n",
    "    return distance.distance((lat1, long1), (lat2, long2)).m\n",
    "\n",
    "def lat(i):\n",
    "    return site_lat_long.loc[i, \"Lat\"]\n",
    "\n",
    "def long(i):\n",
    "    return site_lat_long.loc[i, \"Long\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_closest = 13\n",
    "closest = [[] for i in range(n_nodes)]\n",
    "for i in range(n_nodes):\n",
    "    cur_dists = []\n",
    "    for j in range(n_nodes):\n",
    "        dist = get_dist_lat_long(lat(i), long(i), lat(j), long(j))\n",
    "        cur_dists.append((dist, j))\n",
    "    cur_dists.sort()\n",
    "    # taket the top n_closest\n",
    "    for j in range(n_closest):\n",
    "        closest[i].append(cur_dists[j][1])\n",
    "\n",
    "closest[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals = []\n",
    "for i in range(n_nodes):\n",
    "    vals.append(get_dist_lat_long(lat(i), long(i), lat(closest[i][-1]), long(closest[i][-1])))\n",
    "mean = sum(vals) / len(vals)\n",
    "mean\n",
    "\n",
    "# mean dist between node and its farthest closest node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def centre_i_neighbours(i):\n",
    "    lt = sum(lat(j) for j in closest[i]) / n_closest\n",
    "    lg = sum(long(j) for j in closest[i]) / n_closest\n",
    "    return lt, lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_closest_to_centre(i):\n",
    "    centre = centre_i_neighbours(i)\n",
    "    cur_dists = []\n",
    "    for j in closest[i]:\n",
    "        dist = get_dist_lat_long(centre[0], centre[1], lat(j), long(j))\n",
    "        cur_dists.append((dist, j))\n",
    "    cur_dists.sort()\n",
    "    return list(map(lambda x: x[1], cur_dists))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_neighbours(seed_node):\n",
    "    return get_closest_to_centre(seed_node)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select random node from 0 to n_nodes\n",
    "node = random.randint(0, n_nodes)\n",
    "display(node, sample_neighbours(node))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sample a time and node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_mask = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_volume(node, time):\n",
    "    val = df[(df[\"Site\"] == node) & (df[\"Time\"] == time)][\"Volume\"].values[0]\n",
    "    # round off to the nearest 25 multiple\n",
    "    val = round(val / 25)\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample():\n",
    "    try:\n",
    "        time = df[\"Time\"].sample().values[0]\n",
    "        node = random.randint(0, n_nodes)\n",
    "        \n",
    "        neighbours = sample_neighbours(node)\n",
    "\n",
    "        # miss the first n_mask neighbours\n",
    "        vols = [get_volume(neighbour, time) for neighbour in neighbours]\n",
    "        missing_sum = sum(vols[:n_mask])\n",
    "        og_vols = vols[:n_mask]\n",
    "        rem_vols = vols[n_mask:]\n",
    "\n",
    "        return time, neighbours, missing_sum, rem_vols, og_vols\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time_vector(time):\n",
    "    time = datetime.strptime(time, '%Y-%m-%d %H:%M:%S')\n",
    "    month = time.month\n",
    "    day = time.day\n",
    "    hour = time.hour\n",
    "    return month, day, hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_n(n):\n",
    "    samples = []\n",
    "    while len(samples) < n:\n",
    "        s = sample()\n",
    "        if s:\n",
    "            samples.append(s)\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### creating a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = 1000\n",
    "n_test = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_path = \"./datasets/scats/2023/3m/graph_emb_3m.pt\"\n",
    "embeddings = torch.load(embeddings_path, map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_time_to_feature(time):\n",
    "    # Parse the input time string into a datetime object\n",
    "    time_obj = datetime.strptime(time, \"%Y-%m-%d %H:%M:%S\")\n",
    "    \n",
    "    # Extract hour\n",
    "    hour = time_obj.hour\n",
    "    \n",
    "    # Determine if it's a weekday or weekend (Monday is 0 and Sunday is 6)\n",
    "    weekday_or_weekend = 0 if time_obj.weekday() < 5 else 1\n",
    "    \n",
    "    # Convert features into a PyTorch tensor\n",
    "    features_tensor = torch.tensor([hour, weekday_or_weekend], dtype=torch.float32)\n",
    "    \n",
    "    # Return the tensor\n",
    "    return features_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset(count):\n",
    "    samples = sample_n(count)\n",
    "    X = []\n",
    "    Y = []\n",
    "    for samp in samples:\n",
    "        time, nodes, sum_miss, rem_vols, og_vols = samp\n",
    "\n",
    "        x = [ encode_time_to_feature(time) ]\n",
    "        x.extend([ embeddings[i]  for i in nodes ])\n",
    "        x.append( torch.tensor(get_weather(*get_time_vector(time), lat(nodes[0]), long(nodes[0])) ) )\n",
    "        x.append(torch.tensor([sum_miss]))\n",
    "        x.append(torch.tensor(rem_vols))\n",
    "        # flatten to 1 dim\n",
    "        x = torch.cat(x).view(-1)\n",
    "\n",
    "        X.append(x)\n",
    "        Y.append(torch.tensor(og_vols))\n",
    "    \n",
    "    X = torch.stack(X)\n",
    "    Y = torch.stack(Y)\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX, trainY = generate_dataset(100)\n",
    "display(trainX.shape, trainY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save tensors\n",
    "torch.save(trainX, \"./datasets/scats/2023/3m/train3X100.pt\")\n",
    "torch.save(trainY, \"./datasets/scats/2023/3m/train3Y100.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testX, testY = generate_dataset(100)\n",
    "torch.save(testX, \"./datasets/scats/2023/3m/test3X100.pt\")\n",
    "torch.save(testY, \"./datasets/scats/2023/3m/test3Y100.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
