\chapter*{Abstract}

We explore advancements in Hindi text summarization, a critical area in natural language processing that aids in managing the information overload in today's digital age. Despite the growing corpus of Hindi language data, there remains a significant gap in effective summarization tools, primarily due to the intricate linguistic features and limited resources compared to English. Previous works have focused on extractive summarization methods, but recent developments have shifted towards abstractive approaches, which promise more natural and coherent summaries by understanding and paraphrasing content. Our research introduces novel methodologies, \textbf{N}amed \textbf{E}ntity-\textbf{A}ware \textbf{A}bstractive \textbf{T}ext \textbf{S}ummarization (NEA-ATS) and \textbf{Q}uery-\textbf{D}riven \textbf{C}ontent \textbf{A}ugmentation for \textbf{S}ummarization (QDCAS), aimed at enhancing the factual accuracy and richness of Hindi summaries. Our NEA-ATS method integrates Named Entity Recognition to prioritize crucial information, improving a language model's attention to key details in the texts.  While NEA-ATS shows some improvements, it occasionally disrupts the text's context, leading to only marginal gains in summary quality.  Meanwhile, QDCAS addresses extrinsic hallucinations—common in state-of-the-art language models—by augmenting the source document with relevant content fetched through focused web crawling. QDCAS, not only broadens the contextual understanding in language models but also refines the output by incorporating comprehensive world knowledge. Empirical results demonstrate the effectiveness of QDCAS, showing marked improvements in ROUGE and BERTScores over traditional language models by more than 1\%. This work not only advances the field of Hindi text summarization but also sets the stage for further explorations into optimizing content-rich summarization strategies, potentially expanding to other languages and domains.