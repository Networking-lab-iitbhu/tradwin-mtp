{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AfHOafjdt8wS"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import numpy as np\n",
        "from tqdm.notebook import tqdm_notebook as tqdm\n",
        "from torch.utils.data import DataLoader, TensorDataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p8xyt0JcI4yK"
      },
      "outputs": [],
      "source": [
        "device = \"cpu\"  # or \"cuda\"\n",
        "dataset_type = \"10k\"\n",
        "colab = True  # or True\n",
        "batch_size = 40"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWVSL9PfI4yL"
      },
      "source": [
        "### Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KxSnnEp0I4yN"
      },
      "outputs": [],
      "source": [
        "shuf = True\n",
        "def reset():\n",
        "    if device == \"cuda\":\n",
        "      torch.cuda.empty_cache()\n",
        "    global X, Y, inp_len, out_len, dataloader\n",
        "\n",
        "    pathX = f\"./datasets/scats/2023/3m/t1_tr1kx.pt\"\n",
        "    pathY = f\"./datasets/scats/2023/3m/t1_tr1ky.pt\"\n",
        "    pathEval = f\"./datasets/scats/2023/3m/eval.pt\"\n",
        "\n",
        "    if colab:\n",
        "        from google.colab import drive\n",
        "        drive.mount('/content/drive', force_remount=False)\n",
        "        pathX = f\"./drive/MyDrive/t2x.pt\"\n",
        "        pathY = f\"./drive/MyDrive/t1y.pt\"\n",
        "        pathEval = f\"./datasets/scats/2023/3m/eval.pt\"\n",
        "\n",
        "    X = torch.load(pathX)\n",
        "    Y = torch.load(pathY)\n",
        "    XE = torch.load(pathEval)\n",
        "\n",
        "    # float32\n",
        "    X = X.float()\n",
        "    Y = Y.float()\n",
        "\n",
        "    if device == \"cuda\":\n",
        "        X = X.cuda()\n",
        "        Y = Y.cuda()\n",
        "\n",
        "    inp_len = X.shape[1]*X.shape[2]\n",
        "    out_len = inp_len\n",
        "\n",
        "    dataset = TensorDataset(X, Y)\n",
        "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=shuf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e-jDryDHI4yN"
      },
      "outputs": [],
      "source": [
        "def reset_toy():\n",
        "    torch.cuda.empty_cache()\n",
        "    global X, Y, inp_len, out_len, dataloader\n",
        "\n",
        "    def tranform(x):\n",
        "        return x * 2 + 1\n",
        "    len = 50\n",
        "    X = torch.rand(len, 1) * 5\n",
        "    X.float()\n",
        "    Y = torch.tensor([tranform(x) for x in X])\n",
        "    if device == \"cuda\":\n",
        "        X = X.cuda()\n",
        "        Y = Y.cuda()\n",
        "    Y.unsqueeze_(-1)\n",
        "    Y.float()\n",
        "    inp_len = X.shape[1]*X.shape[2]\n",
        "    out_len = inp_len\n",
        "    dataset = TensorDataset(X, Y)\n",
        "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aph9N9TQt8wU",
        "outputId": "e63f67de-e16c-4ac1-9e46-d54483ecd12f"
      },
      "outputs": [],
      "source": [
        "reset()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "geQ-WhywI4yN"
      },
      "source": [
        "### Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UhzWyVZ06jSf"
      },
      "outputs": [],
      "source": [
        "def sample_M(m, n, p):\n",
        "    A = np.random.uniform(0., 1., size=[m, n])\n",
        "    B = A > p\n",
        "    C = 1. * B\n",
        "    return C\n",
        "\n",
        "def sample_idx(m, n):\n",
        "    A = np.random.permutation(m)\n",
        "    idx = A[:n]\n",
        "    return idx\n",
        "\n",
        "def sample_Z(m, n, high):\n",
        "    return np.random.uniform(0., high, size=[m, n])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "xtiG4ViKt8wV",
        "outputId": "aa467529-535f-4bba-972a-9ced152c5071"
      },
      "outputs": [],
      "source": [
        "miss_rate = 0.1\n",
        "\n",
        "def mask_for_one():\n",
        "    mask = sample_M(X.shape[1], 3, miss_rate)\n",
        "    ones = np.ones(X[0].shape)\n",
        "    ones[:, -3:] = mask\n",
        "    return ones\n",
        "\n",
        "\n",
        "mask = []\n",
        "for i in range(X.shape[0]):\n",
        "    mask.append(mask_for_one())\n",
        "\n",
        "# to tensor\n",
        "mask = torch.tensor(mask).float()\n",
        "\n",
        "if device == \"cuda\":\n",
        "  mask = mask.cuda()\n",
        "display(mask.shape)\n",
        "\n",
        "dataset = TensorDataset(X, mask)\n",
        "a,b = dataset[0]\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=shuf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qi3cGPW6AkLY"
      },
      "outputs": [],
      "source": [
        "def discriminator_loss(netG, netD, M, X, H):\n",
        "    G_sample = netG(X, M)\n",
        "    Hat_New_X = X * M + G_sample * (1-M)\n",
        "    D_prob = netD(Hat_New_X, H)\n",
        "    D_loss = -torch.mean(M * torch.log(D_prob + 1e-8) +\n",
        "                         (1-M) * torch.log(1. - D_prob + 1e-8))\n",
        "    return D_loss\n",
        "\n",
        "\n",
        "def generator_loss(netG, netD, X, M, New_X, H):\n",
        "    alpha = 2\n",
        "    G_sample = netG(New_X, M)\n",
        "    Hat_New_X = New_X * M + G_sample * (1-M)\n",
        "    D_prob = netD(Hat_New_X, H)\n",
        "    G_loss1 = -torch.mean((1-M) * torch.log(D_prob + 1e-8))\n",
        "    MSE_train_loss = torch.mean((M*New_X -M* G_sample)**2)\n",
        "    G_loss = G_loss1 + alpha * MSE_train_loss\n",
        "    MSE_test_loss = torch.mean(\n",
        "        ((1-M) * X - (1-M)*G_sample)**2) / torch.mean(1-M)\n",
        "    return G_loss, MSE_train_loss, MSE_test_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hFzex3_3_vp1"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "def calculate_rmse(actual, predicted):\n",
        "    assert actual.shape == predicted.shape, \"Matrices must have the same shape\"\n",
        "    actual = actual[:,:,-3:]\n",
        "    predicted = predicted[:,:,-3:]\n",
        "    squared_differences = (actual - predicted) ** 2\n",
        "    mean_squared_error = torch.mean(squared_differences)\n",
        "    rmse = torch.sqrt(mean_squared_error)\n",
        "\n",
        "    return rmse.item()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EqNTsIQSCQQb"
      },
      "outputs": [],
      "source": [
        "def calculate_mape(actual, predicted, epsilon=3):\n",
        "    # Ensure the matrices have the same shape\n",
        "    assert actual.shape == predicted.shape, \"Matrices must have the same shape\"\n",
        "    actual = actual[:,:,-3:]\n",
        "    predicted = predicted[:,:,-3:]\n",
        "\n",
        "    mask = torch.abs(actual) > epsilon\n",
        "\n",
        "    actual_filtered = actual[mask]\n",
        "    predicted_filtered = predicted[mask]\n",
        "\n",
        "    absolute_percentage_errors = torch.abs((actual_filtered - predicted_filtered) / actual_filtered)\n",
        "\n",
        "    mape = torch.mean(absolute_percentage_errors) * 100\n",
        "\n",
        "    return mape.item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hsTud7mfI4yP",
        "outputId": "10d2728e-a77e-405d-954c-d45c87a4950d"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "\n",
        "# Generator network\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(Generator, self).__init__()\n",
        "        layer_dims = [2*input_dim, 1024, 512, input_dim]\n",
        "        layers = []\n",
        "        for i in range(len(layer_dims) - 1):\n",
        "            layers.append(nn.Linear(layer_dims[i], layer_dims[i+1]))\n",
        "            if i < len(layer_dims) - 2:\n",
        "                layers.append(nn.ReLU())\n",
        "        self.layers = layers\n",
        "        self.model = nn.Sequential(*layers)\n",
        "        self.init_weight()\n",
        "\n",
        "    def init_weight(self):\n",
        "        layers = self.layers\n",
        "        [torch.nn.init.xavier_normal_(layer.weight) for layer in layers if isinstance(layer, nn.Linear)]\n",
        "\n",
        "    def forward(self, x, m):\n",
        "        inp = torch.cat([x, m], dim=1)\n",
        "        # display(inp.shape)\n",
        "        out = self.model(inp)\n",
        "        return out\n",
        "        # return x*m + out*(1-m)\n",
        "\n",
        "# Discriminator network\n",
        "\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        # display(input_dim)\n",
        "        super(Discriminator, self).__init__()\n",
        "        layer_dims = [2*input_dim, 1024, 512, input_dim]\n",
        "        layers = []\n",
        "        for i in range(len(layer_dims) - 1):\n",
        "            layers.append(nn.Linear(layer_dims[i], layer_dims[i+1]))\n",
        "            if i < len(layer_dims) - 2:\n",
        "                layers.append(nn.ReLU())\n",
        "        self.layers = layers\n",
        "        self.model = nn.Sequential(*layers)\n",
        "\n",
        "    def init_weight(self):\n",
        "        layers = self.layers\n",
        "        [torch.nn.init.xavier_normal_(layer.weight) for layer in layers if isinstance(layer, nn.Linear)]\n",
        "\n",
        "    def forward(self, x, m):\n",
        "        inp = torch.cat([x, m], dim=1)\n",
        "        return self.model(inp)\n",
        "\n",
        "\n",
        "G = Generator(inp_len)\n",
        "D = Discriminator(inp_len)\n",
        "optim_G = optim.Adam(G.parameters(), lr=2e-4)\n",
        "optim_D = optim.Adam(D.parameters(), lr=2e-4)\n",
        "data_iter = iter(dataloader)\n",
        "\n",
        "if device == \"cuda\":\n",
        "    G = G.cuda()\n",
        "    D = D.cuda()\n",
        "\n",
        "# criterion = nn.BCELoss()\n",
        "\n",
        "mb_size = batch_size\n",
        "hr = 0.5\n",
        "\n",
        "\n",
        "def gradient_penalty(D, xr, xf):\n",
        "    \"\"\"\n",
        "\n",
        "    :param D:\n",
        "    :param xr: [b, 2]\n",
        "    :param xf: [b, 2]\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    # [b, 1]\n",
        "    t = torch.rand(batch_size, 1).cuda()\n",
        "    # [b, 1] => [b, 2]  broadcasting so t is the same for x1 and x2\n",
        "    t = t.expand_as(xr)\n",
        "    # interpolation\n",
        "    mid = t * xr + (1 - t) * xf\n",
        "    # set it to require grad info\n",
        "    mid.requires_grad_()\n",
        "\n",
        "    pred = D(mid)\n",
        "    grads = torch.autograd.grad(outputs=pred, inputs=mid,\n",
        "                                grad_outputs=torch.ones_like(pred),\n",
        "                                create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
        "\n",
        "    gp = torch.pow(grads.norm(2, dim=1) - 1, 2).mean()\n",
        "\n",
        "    return gp\n",
        "\n",
        "\n",
        "# Training loop\n",
        "epochs = 1000\n",
        "for epoch in range(epochs):\n",
        "    cnt = 0\n",
        "    sum = 0\n",
        "    for di,(Xi, Msk) in enumerate(dataloader):\n",
        "        # display(Xi.shape, Msk.shape)\n",
        "        for _ in range(1):\n",
        "            X_mb = Xi\n",
        "            X_mb = X_mb.view(mb_size, -1)\n",
        "            Z_mb = sample_Z(mb_size, inp_len, 900)\n",
        "\n",
        "            M_mb = Msk.view(mb_size, -1)\n",
        "            if device == \"cuda\":\n",
        "              M_mb = torch.tensor(M_mb, device=\"cuda\").float()\n",
        "              X_mb = torch.tensor(X_mb, device=\"cuda\").float()\n",
        "              Z_mb = torch.tensor(Z_mb, device=\"cuda\").float()\n",
        "            Hnt = sample_M(mb_size, inp_len, 1-hr)\n",
        "            if device == \"cuda\":\n",
        "              Hnt = torch.tensor(Hnt, device=\"cuda\").float()\n",
        "            H_mb = M_mb * Hnt\n",
        "            X_noisy = M_mb * X_mb + (1-M_mb) * Z_mb\n",
        "\n",
        "            if device == \"cuda\":\n",
        "                X_mb = torch.tensor(X_mb, device=\"cuda\").float()\n",
        "                M_mb = torch.tensor(M_mb, device=\"cuda\").float()\n",
        "                H_mb = torch.tensor(H_mb, device=\"cuda\").float()\n",
        "                X_noisy = torch.tensor(X_noisy, device=\"cuda\").float()\n",
        "                Z_mb = torch.tensor(Z_mb, device=\"cuda\").float()\n",
        "            else:\n",
        "                X_mb = torch.tensor(X_mb).float()\n",
        "                M_mb = torch.tensor(M_mb).float()\n",
        "                H_mb = torch.tensor(H_mb).float()\n",
        "                X_noisy = torch.tensor(X_noisy).float()\n",
        "                Z_mb = torch.tensor(Z_mb).float()\n",
        "\n",
        "\n",
        "            optim_D.zero_grad()\n",
        "            Dl = discriminator_loss(G, D, M_mb, X_noisy, H_mb)\n",
        "            Dl.backward()\n",
        "            optim_D.step()\n",
        "\n",
        "        # train G\n",
        "        optim_G.zero_grad()\n",
        "        Gl, _,_ = generator_loss(G, D, X_mb, M_mb, X_noisy, H_mb)\n",
        "        # print(f\"loss: {Gl.item()}\" )\n",
        "        Gl.backward()\n",
        "        optim_G.step()\n",
        "\n",
        "        out = G(X_mb, M_mb)\n",
        "        out = out.reshape(mb_size, X.shape[1], X.shape[2])\n",
        "\n",
        "        print(f\"Itr {epoch}/{di} RMSE: {calculate_rmse(out, Xi)} MAPE: {calculate_mape(out, Xi)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ill8OeB9I4yQ"
      },
      "outputs": [],
      "source": [
        "# idx = 1\n",
        "# sample = X[idx].flatten().unsqueeze(dim = 0)\n",
        "# mmm = mask[idx].flatten().unsqueeze(dim = 0)\n",
        "# res = G(sample, mmm)\n",
        "# res = res.squeeze().view(X.shape[1],X.shape[2])\n",
        "# display(res[:,-3:])\n",
        "# display(X[idx][:,-3:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EufAbCBRQuPB"
      },
      "outputs": [],
      "source": [
        "# # for entire data MAPE\n",
        "# def eval():\n",
        "#     G.eval()\n",
        "#     sz = X.shape[0]\n",
        "#     sz2 = 3\n",
        "#     mape = 0\n",
        "#     tot = 0\n",
        "#     for i in range(sz):\n",
        "#         res = G.forward(X[i].flatten().detach(), mask[i].flatten().detach()).detach()\n",
        "#         for node in range(X[i].shape[0]):\n",
        "#             for j in range(sz2):\n",
        "#                 if (abs(X[i][node][j]-1e-6) < 1e-4):\n",
        "#                     continue\n",
        "#                 mape += abs(res[node][j]-Y[i][node][j])/(Y[i][node][j]+1e-18)\n",
        "#                 tot += 1\n",
        "#     return mape/tot\n",
        "\n",
        "\n",
        "# eval()*100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQUMeF--t8wW",
        "outputId": "1589f7c6-437d-41b0-ac23-9ff6cfd04070"
      },
      "outputs": [],
      "source": [
        "def eval():\n",
        "  G.eval()\n",
        "  Z = sample_Z(X.shape[0], inp_len, 900)\n",
        "  Z = torch.tensor(Z, device=device).float()\n",
        "  X_eval = X.view(X.shape[0], X.shape[1]*X.shape[2])\n",
        "  M_eval = mask.view(X.shape[0], X.shape[1]*X.shape[2])\n",
        "  X_noisy = M_eval*X_eval + (1-M_eval)*Z\n",
        "  out = G(X_noisy, M_eval)\n",
        "  out = out.reshape(X.shape[0], X.shape[1], X.shape[2])\n",
        "  mape = calculate_mape(out,X)\n",
        "  rmse = calculate_rmse(out,X)\n",
        "  print(f\"mape: {mape} rmse: {rmse}\")\n",
        "\n",
        "eval()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
